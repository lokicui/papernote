
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{url}
%\urldef{\mailsa}\path|{alfred.hofmann, ursula.barth, ingrid.haas, frank.holzwarth,|
%\urldef{\mailsb}\path|anna.kramer, leonie.kunz, christine.reiss, nicole.sator,|
%\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
%\newcommand{\keywords}[1]{\par\addvspace\baselineskip
%\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter  % start of an individual contribution

% first the title is needed
\title{DLDE at web track: ad-hoc task note}

% a short form should be given in case it is too long for the running head
\titlerunning{Ad-hoc task note}

% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%
\author{Jie Chen \and Yulong Shi \and Changmin Zhang \and Weiyin Li \and Zhendong Niu}

%
\authorrunning{Notebook to ad-hoc task of web track 2013}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
%\institute{Springer-Verlag, Computer Science Editorial,\\
%Tiergartenstr. 17, 69121 Heidelberg, Germany\\
%\mailsa\\
%\mailsb\\
%\mailsc\\
%\url{http://www.springer.com/lncs}}

%
% NB: a more complex sample for affiliations and the mapping to the
% corresponding authors can be found in the file "llncs.dem"
% (search for the string "\mainmatter" where a contribution starts).
% "llncs.dem" accompanies the document class "llncs.cls".
%

%\toctitle{Lecture Notes in Computer Science}
%\tocauthor{Authors' Instructions}
\maketitle

\begin{abstract}
\emph{In this note paper, we report our experiment method at ad-hoc task of Web Track 2013. The goal of this task is to return a ranking of the documents order by relevance from the collection of static web pages. Our group use meta search to help query expansion as the first step , then do text retrieval with the expansion query to get the search results and rerank them. }
\keywords{Ad-hoc search, query expansion , meta search}
\end{abstract}

\section{Introduction}

The ad-hoc task of web track is based on some given topics to search out the most relevant documents from a large number of static web pages, ClueWeb2012 \cite{clueweb2012}, which comprises about 870 million web pages, collected between February 10, 2012 and May 10, 2012. Topics are similar to queries of tradition web search, short and ambiguity. It's hard to get better search results based on keywords match method. This year we use the WebClue2012-B13 dataset , a subset of WebClue2012 with 50 million web pages.First, we do some prepare word to the dataset in order to remove the spams and noise data. Second, in order to get more semantic meanings, we use meta search approach to get some pages relevant to the topic as seeds , then we can compute the semantic words as expansion. Third, we rerank the search results from the treated data with the expansion query. 

\section{Data preprocessing}

Since the data set is too large to operate directly and efficiently, we remove the non-relevant  data and spam before doing the final query step. In our experiments , we first use the Indri \cite{indri} tools and waterloo spam \cite{2011-Cormack-p441-465} to build the raw index files. Second, we get all the relevant pages from the index with the topic as the query. These relevant pages are the basic data of our experiments. In the process of parsing the web page , we find here are many noises    in body such as advertisements, copy rights, so the Block web content parser \cite{2012-Lin-p256-264} , developed by our lab,  is introduced into this project to extract the main content. Third, we build a new index file with Lucene \cite{lucene} for subsequent experiments.  The reason is that our group already have a web search system based on Lucene package.

\section{Query Search}

We divided the query search phase into two parts: query expansion and reranking. We expand each origin topic to be a sematic word set as new query to get search results and treate them as the final results after reranking. 

\subsection{Query Expansion }

\subsubsection{Meta search}

we use google search and bing search as a meta search resource. each search engine return the top 200 pages about the topic, and we use the page extract technology \cite{linshuang-block} to get main content.  

\subsubsection{Expansion Stractagcy}
Query expansion is a commonly used method help search system to understand the origin query words. In our experiment, we use the local analysis \cite{localanalysis} method to get the expansion words. By calculating occurrence number of each word and remove the stop words to get the orgin expansion words list. With the help of Standford Parser \cite{standfordparser} , developed by Standford Natural Language Processing Group, we remove all the words in addition to nouns and get the top 30 as the final expansion words list.

We treate the synonym of origin topic word as the denominator to get the weight of each expansion word
\begin{equation}
w_i = \frac{TF_i}{TF_max}
\end{equation}
.We can get the final query expansion formula as below
\begin{equation}
q_{expan} = q_{origin} + \sum_{i=1}^n w_i * Expan_i
\end{equation}
\subsection{ReRanking}



\section{Experiments}

This year we submit only one run and it performs bad. In the 

\section{Conculion and Feature}

We described our approach in this paper. This year we use web content technology to remove the noise of web page and use the meta search and query expansion method to understand the topic. But the final run performs bad. In the next year , we will use the whole dataset of ClueWeb2012 to verify our approach.

\section{Acknowledge}

\section{References}





\end{document}
